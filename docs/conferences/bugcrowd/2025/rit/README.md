# Rochester Institute of Technology - LLM AI AppSec Workshop

## BugCrowd College Program Educational Event

- **Institution:** Rochester Institute of Technology (RIT)
- **Program:** BugCrowd College Program
- **Session Type:** Internal Educational Event
- **Duration:** 90 minutes (flexible format)
- **Format:** Technical demonstration and practical workshop

### Workshop Overview

This internal educational workshop is designed specifically for RIT students as part of the BugCrowd College Program. The session focuses on Large Language Model (LLM) Application Security, covering both theoretical concepts and hands-on practical exercises.

### Session Structure (0-90 minutes, flexible)

**Part 1: Overview & Fundamentals (30 minutes)**
- Introduction to LLM Application Security landscape
- Common vulnerability patterns in AI applications
- OWASP Top 10 for LLM Applications overview
- Real-world case studies and attack scenarios

**Part 2: Technical Demonstrations (30 minutes)**
- Live demonstrations of common LLM vulnerabilities
- Prompt injection techniques and mitigation strategies
- Model poisoning and data extraction attacks
- AI red teaming methodologies

**Part 3: Hands-On Workshop (30 minutes)**
- Practical exercises tailored to student skill levels
- Guided vulnerability discovery in sample LLM applications
- Tool demonstrations (dependent on technical setup)
- Q&A and troubleshooting session

### Learning Objectives

Students will learn to:
- **Identify** common security risks in LLM applications
- **Understand** attack vectors specific to AI/ML systems
- **Apply** basic security testing techniques to AI applications
- **Recognize** the importance of secure AI development practices
- **Develop** foundational skills for AI security careers

### Technical Requirements

- **Skill Level:** Adaptable (basic to intermediate cybersecurity knowledge)
- **Equipment:** Student laptops recommended for hands-on portions
- **Prerequisites:** Basic understanding of web applications helpful but not required
- **Tools:** Browser-based demonstrations and exercises

### Educational Impact

This workshop represents BugCrowd's commitment to educating the next generation of security professionals, specifically in the rapidly evolving field of AI application security. Students gain practical exposure to cutting-edge security challenges in the AI/ML space.

### Speaker Bio

> Ads is a web application pentester, seasoned bug bounty hunter, and BugCrowd Hacker Advisory Board Member with over 15 years of offensive security experience. As co-author of "AI Native LLM Security" and Board member of the OWASP Top 10 for LLM Applications project, he brings deep expertise in AI security to educational settings. He actively mentors students and early-career professionals entering the cybersecurity field.

---

**Workshop Details:**
- **Target Audience:** RIT Computer Science and Cybersecurity students
- **Delivery Method:** Interactive presentation with hands-on components
- **Customization:** Content adapted based on student background and interests
- **Follow-up:** Resources provided for continued learning

ðŸŽ“ **College Program Integration:** Part of BugCrowd's broader initiative to train student researchers in modern cybersecurity challenges