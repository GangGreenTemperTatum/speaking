{
  "conferences": [
    {
      "id": "apidays-2023",
      "name": "API Days",
      "path": "apidays",
      "year": "2023",
      "icon": "fas fa-cloud",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "apisec-2023",
      "name": "APISec",
      "path": "apisec",
      "year": "2023",
      "icon": "fas fa-shield-alt",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "bugcrowd-2025-july-bugboss-2025",
      "name": "BugBoss",
      "path": "bugcrowd/2025/july/bugboss",
      "year": "2025",
      "icon": "fas fa-bug",
      "description": "BugCrowd Bugboss v3 Show and Tell"
    },
    {
      "id": "bugcrowd-2025-july-rhic-2025",
      "name": "RHIC",
      "path": "bugcrowd/2025/july/rhic",
      "year": "2025",
      "icon": "fas fa-bug",
      "description": "BugCrowd x Dreadnode Crucible: Rhode Island College Cyber Range"
    },
    {
      "id": "bugcrowd-2025-october-wraven-2025",
      "name": "WRAVEN x BugCrowd",
      "path": "bugcrowd/2025/october/wraven",
      "year": "2025",
      "icon": "fas fa-bug",
      "description": "Bug Bounty Student Training by Bugcrowd"
    },
    {
      "id": "dc604-2023",
      "name": "DC604",
      "path": "dc604",
      "year": "2023",
      "icon": "fas fa-users",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "defcon-2025",
      "name": "DEFCON",
      "path": "defcon/2025/august/bb_village",
      "year": "2025",
      "icon": "fas fa-skull-crossbones",
      "description": "Misaligned: AI Jailbreaking Panel with Basi Team Six (BT6) & Jason Haddix"
    },
    {
      "id": "in-cyber-forum-2024",
      "name": "In-Cyber Forum",
      "path": "in-cyber-forum",
      "year": "2024",
      "icon": "fas fa-globe",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "interface-2023",
      "name": "Interface",
      "path": "interface",
      "year": "2023",
      "icon": "fas fa-code",
      "description": "Language AI Security at the API level - Avoiding Hacks, Injections and Breaches"
    },
    {
      "id": "isaca-2024",
      "name": "ISACA",
      "path": "isaca",
      "year": "2024",
      "icon": "fas fa-certificate",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "isc2-2025",
      "name": "ISC2",
      "path": "isc2",
      "year": "2025",
      "icon": "fas fa-certificate",
      "description": "Behind the Prompt: Exposing and Mitigating the Top LLM Vulnerabilities"
    },
    {
      "id": "lakera-2023",
      "name": "Lakera AI",
      "path": "lakera/december/2023",
      "year": "2023",
      "icon": "fas fa-shield-alt",
      "description": "How to Secure AI Applications: Lessons from OWASP's Top 10 for LLMs"
    },
    {
      "id": "lakera-2024",
      "name": "Lakera AI",
      "path": "lakera/april/2024",
      "year": "2024",
      "icon": "fas fa-shield-alt",
      "description": "Decoding OWASP Large Language Model Security Verification Standard (LLMSVS)"
    },
    {
      "id": "mako-lab-2023",
      "name": "Mako Lab",
      "path": "mako-lab",
      "year": "2023",
      "icon": "fas fa-flask",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "mako-lab-2024",
      "name": "Mako Lab",
      "path": "mako-lab",
      "year": "2024",
      "icon": "fas fa-flask",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "mlopscommunity-2024",
      "name": "MLOps Community",
      "path": "mlopscommunity",
      "year": "2024",
      "icon": "fas fa-cogs",
      "description": "AI in Production - MLOps Security and Privacy Panel"
    },
    {
      "id": "offbyonesecurity-2025",
      "name": "Off By One Security",
      "path": "offbyonesecurity/2025/july",
      "year": "2025",
      "icon": "fas fa-bug",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "owasp/owasp-cairo-2025",
      "name": "OWASP CAIRO",
      "path": "owasp/owasp-cairo",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "owasp-owasp-toronto-2024-june",
      "name": "OWASP TORONTO",
      "path": "owasp/owasp-toronto/2024/june",
      "year": "2024",
      "icon": "fas fa-shield-virus",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "owasp-owasp-toronto-2025-march",
      "name": "OWASP TORONTO",
      "path": "owasp/owasp-toronto/2025/march",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "How to Utilize AI in Offensive Security—An Intro to Offensive AI Tooling"
    },
    {
      "id": "owasp-owasp-toronto-2025-september",
      "name": "OWASP TORONTO",
      "path": "owasp/owasp-toronto/2025/september",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "Becoming a Caido Power User: From Recon to Root"
    },
    {
      "id": "owasp/owasp-vancouver-2023",
      "name": "OWASP VANCOUVER",
      "path": "owasp/owasp-vancouver",
      "year": "2023",
      "icon": "fas fa-shield-virus",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "owasp/owasp-atlanta-2025",
      "name": "OWASP ATLANTA",
      "path": "owasp/owasp-atlanta",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "owasp/owasp-llm-apps-2025",
      "name": "OWASP LLM Apps Project",
      "path": "owasp/owasp-llm-apps",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "Sandboxing AI Models with Dyana & OWASP Top 10 for LLM Apps"
    },
    {
      "id": "rsa-usa-2024",
      "name": "RSA Conference",
      "path": "rsa-usa",
      "year": "2024",
      "icon": "fas fa-lock",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    },
    {
      "id": "rsa-usa-2025",
      "name": "RSA Conference",
      "path": "rsa-usa",
      "year": "2025",
      "icon": "fas fa-lock",
      "description": "Talks on AI/ML Security and LLM Application Safety"
    }
  ],
  "podcasts": [
    {
      "id": "podcasts-bareknuckles_and_brass_tacks-2024",
      "name": "Bare Knuckles and Brass Tacks",
      "path": "podcasts/bareknuckles_and_brass_tacks",
      "year": "2024",
      "icon": "fas fa-fist-raised",
      "description": "Discussion about AI and ML security"
    },
    {
      "id": "podcasts-chai_chat_podcast-2023",
      "name": "ChAI Chat Podcast",
      "path": "podcasts/chai_chat_podcast",
      "year": "2023",
      "icon": "fas fa-mug-hot",
      "description": "Conversations on AI ethics and security challenges"
    },
    {
      "id": "podcasts-f5_dev_central-2023",
      "name": "F5 DevCentral",
      "path": "podcasts/f5_dev_central",
      "year": "2023",
      "icon": "fas fa-server",
      "description": "Discussion about AI and ML security"
    },
    {
      "id": "podcasts-mlops_community-2023-november-2023",
      "name": "MLOps Community",
      "path": "podcasts/mlops_community/2023/november",
      "year": "2023",
      "icon": "fas fa-cogs",
      "description": "Exploring the intersection of MLOps and security"
    },
    {
      "id": "podcasts-owasp-owasp-llm-apps-podcast-2024",
      "name": "OWASP LLM Apps Podcast",
      "path": "podcasts/owasp/owasp-llm-apps-podcast",
      "year": "2024",
      "icon": "fas fa-shield-virus",
      "description": "Security considerations for LLM applications"
    },
    {
      "id": "podcasts-owasp-owasp-llm-apps-podcast-2025",
      "name": "OWASP LLM Apps Podcast",
      "path": "podcasts/owasp/owasp-llm-apps-podcast",
      "year": "2025",
      "icon": "fas fa-shield-virus",
      "description": "Sandboxing AI Models with Dyana & OWASP Top 10 for LLM Apps - Ep.4"
    },
    {
      "id": "podcasts-software_testing_and_quality_talks-2024",
      "name": "Software Testing & Quality Talks",
      "path": "podcasts/software_testing_and_quality_talks",
      "year": "2024",
      "icon": "fas fa-check-circle",
      "description": "Discussion about AI and ML security"
    },
    {
      "id": "podcasts-synack-2023",
      "name": "Synack Podcast",
      "path": "podcasts/synack",
      "year": "2023",
      "icon": "fas fa-bug",
      "description": "Discussion about AI and ML security"
    }
  ],
  "publications": [
    {
      "id": "bugcrowd-author-profile",
      "title": "Bugcrowd Author Profile - Ads Dawson",
      "publisher": "BugCrowd",
      "description": "Complete collection of all my published articles, research, and contributions on the Bugcrowd blog covering API and web application Hacking, AI security, red teaming, and vulnerability research.",
      "url": "https://arxiv.org/abs/2506.14682",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "arxiv-airtbench",
      "title": "arXiv:2506.14682 - AIRTBench: Measuring Autonomous AI Red Teaming Capabilities in Language Models",
      "publisher": "arXiv",
      "description": "Academic paper on an AI red teaming benchmark for evaluating language models' ability to autonomously discover and exploit Artificial Intelligence and Machine Learning (AI/ML) security vulnerabilities.",
      "url": "https://arxiv.org/abs/2506.14682",
      "icon": "fas fa-file-alt",
      "external": true,
      "year": "2025"
    },
    {
      "id": "dreadnode-ai-red-team-benchmark-case-study",
      "title": "AI Red Teaming Case Study: Claude 3.7 Sonnet Solves the Turtle Challenge",
      "publisher": "Dreadnode",
      "description": "Ads reveals groundbreaking research where AI models crushed a cybersecurity challenge so brutal that 94% of human hackers fail—yet three frontier AIs (Claude, Gemini, and Llama) each cracked it using wildly different strategies, from Claude's methodical 9-minute persistence to Llama's lightning-fast 1-minute creative deception. Using their AIRTBench benchmark of 70 AI/ML security challenges and their Strikes evaluation platform, Ads demonstrates that these aren't just pattern-matching machines but genuine problem-solvers adapting under pressure, marking a pivotal moment where AI offensive capabilities have officially surpassed most human experts—and they're sharing the complete dataset so the security community can prepare for what's coming next.",
      "url": "https://dreadnode.io/blog/ai-red-teaming-case-study-claude-sonnet-solves-turtle",
      "icon": "fas fa-skull",
      "year": "2025"
    },
    {
      "id": "dreadnode-ai-red-team-benchmark",
      "title": "Do LLM Agents Have AI Red Team Capabilities? We Built a Benchmark to Find Out",
      "publisher": "Dreadnode",
      "description": "We're excited to introduce AIRTBench, an AI red teaming framework that tests LLMs against AI/ML black-box capture-the-flag (CTF) challenges to see how they perform when attacking other AI systems. Think of it as a proving ground where models face the kind of adversarial scenarios they'd encounter in the wild, not just in carefully curated test suites.",
      "url": "https://dreadnode.io/blog/ai-red-team-benchmark",
      "icon": "fas fa-skull",
      "year": "2025"
    },
    {
      "id": "arxiv-ai-red-teaming",
      "title": "arXiv:2504.19855 - The Automation Advantage in AI Red Teaming",
      "publisher": "arXiv",
      "description": "Academic paper on automated approaches to AI security testing",
      "url": "https://arxiv.org/abs/2504.19855",
      "icon": "fas fa-file-alt",
      "external": true,
      "year": "2024"
    },
    {
      "id": "cohere-ai-security",
      "title": "The State of AI Security",
      "publisher": "Cohere",
      "description": "An in-depth look at current AI security challenges",
      "url": "https://cohere.com/blog/the-state-of-ai-security",
      "icon": "fas fa-brain",
      "external": true,
      "year": "2023"
    },
    {
      "id": "cohere-straight-talk",
      "title": "Straight talk on AI security with Exabeam's Steve Wilson",
      "publisher": "Cohere",
      "description": "Interview discussing AI security challenges and solutions",
      "url": "https://cohere.com/blog/straight-talk-on-ai-security-with-exabeams-steve-wilson",
      "icon": "fas fa-brain",
      "external": true,
      "year": "2023"
    },
    {
      "id": "cohere-gen-ai-changed-security",
      "title": "How generative AI has changed security",
      "publisher": "Cohere",
      "description": "Analysis of the security landscape in the era of generative AI",
      "url": "https://cohere.com/blog/how-generative-ai-has-changed-security-2",
      "icon": "fas fa-brain",
      "external": true,
      "year": "2023"
    },
    {
      "id": "cohere-enterprise-ai-security",
      "title": "Enterprise AI security: Deploying LLM applications safely",
      "publisher": "Cohere",
      "description": "Guidelines for secure enterprise LLM deployment",
      "url": "https://cohere.com/blog/enterprise-ai-security-deploying-llm-applications-safely",
      "icon": "fas fa-brain",
      "external": true,
      "year": "2023"
    },
    {
      "id": "bugcrowd-hacked-my-way",
      "title": "How I hacked my way to the big leagues: Fat bounties, interviews on NASDAQ, and advisory boards",
      "publisher": "BugCrowd",
      "description": "Breaking things for fun and profit - Though Leadership",
      "url": "https://www.bugcrowd.com/blog/how-i-hacked-my-way-to-the-big-leagues-fat-bounties-interviews-on-nasdaq-and-advisory-boards/",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "bugcrowd-agents-rigging",
      "title": "Rigging the system: The art of AI exploits",
      "publisher": "BugCrowd",
      "description": "Leveraging agents, crafting exploits, and mining the hidden gems of AI security",
      "url": "https://www.bugcrowd.com/blog/rigging-the-system-the-art-of-ai-exploits/",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "bugcrowd-airt-dspy",
      "title": "Hacking AI applications: In the trenches with DSPy",
      "publisher": "BugCrowd",
      "description": "An in-depth exploration of automated AI red teaming using DSPy",
      "url": "https://www.bugcrowd.com/blog/hacking-llm-applications-in-the-trenches-with-dspy/",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "bugcrowd-hacking-llm",
      "title": "Hacking LLM applications: A meticulous hacker's two cents",
      "publisher": "BugCrowd",
      "description": "Insights into vulnerabilities specific to LLM applications",
      "url": "https://www.bugcrowd.com/blog/hacking-llm-applications-a-meticulous-hackers-two-cents/",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "bugcrowd-hacking-sidekick",
      "title": "A low-cost hacking sidekick: Baby steps to using offensive AI agents",
      "publisher": "BugCrowd",
      "description": "Guide to leveraging AI for ethical hacking",
      "url": "https://www.bugcrowd.com/blog/a-low-cost-hacking-sidekick-baby-steps-to-using-offensive-ai-agents/",
      "icon": "fas fa-bug",
      "external": true,
      "year": "2025"
    },
    {
      "id": "packt-llm-security-handbook",
      "title": "LLM Security Handbook - Chapter 8: Mitigating LLM Risks",
      "publisher": "Packt Publishing",
      "description": "Strategies and techniques for mitigating risks in LLM applications",
      "url": "/packt/llm_sec_handbook/chapter_8_mitigating_llm_risks-strategies_techniques",
      "icon": "fas fa-book",
      "year": "2024"
    },
    {
      "id": "owasp-top-10-llm",
      "title": "OWASP Top 10 for LLM Applications",
      "publisher": "OWASP",
      "description": "Contributing author to the OWASP Top 10 for LLM Applications guide",
      "url": "/owasp/owasp-llm-apps",
      "icon": "fas fa-shield-virus",
      "year": "2023"
    }
  ]
}